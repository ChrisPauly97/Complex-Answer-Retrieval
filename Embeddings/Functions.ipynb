{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code playground for generating query expansions based on embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Format Input Queries and Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#     broadQuery = independentRelevance(testQuery)\n",
    "#     fineQuery = independentRelevanceFine(testQuery)\n",
    "    \n",
    "#     # If there are no results, skip the remaining checks\n",
    "#     if(fineQuery == [] and broadQuery == ['',[]]):\n",
    "#         print(\"This query \\\"\" + testQuery + \"\\\" does not have any relevant expansions\")\n",
    "#         print(\"--------------------------------------------------------\")\n",
    "# #         continue\n",
    "#     # If there is a broad query, print it\n",
    "#     # This can still occur even if there are no fine results?\n",
    "#     if(broadQuery != ['',[]]):\n",
    "#         print(\"\\n\\033[1m Broad: \\033[0m\\'\" + testQuery + \"\\\" = \\n\" + '\\n'.join(str(broadQuery[1]).split(\",\")))\n",
    "#     else:\n",
    "#         print(\"There are no broad results for this query\")\n",
    "\n",
    "#     # If there is a fine query found from the broadQuery results, print it\n",
    "#     if(fineQuery != {}):\n",
    "#         print(\"\\n\\033[1m Fine : \\033[0m\\'\"+ testQuery + \"\\\" = \\n\" + ' '.join(str(fineQuery).split(\",\")))\n",
    "#     else:\n",
    "#         print(\"There are no fine results using the broadly relevant query words\")\n",
    "#     print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTokenLength = 0\n",
    "def tsne_plot(tokens_input,maxTokenLength):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import sys\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "#     tokens_input = [[\"agriprocessors\", \"bankruptcy\", \"\", \"\", \"\"],\n",
    "#                 [\"agriprocessors\",\"controversies\",\"\",\"\",\"\"],\n",
    "#                 [\"animal\",\"agriprocessors\",\"abuse\",\"controversies\",\"\"],\n",
    "#                 [\"agriprocessors\",\"controversies\",\"federal\",\"immigration\",\"raid\"],\n",
    "#                 [\"agriprocessors\",\"\",\"\",\"\",\"\"]]\n",
    "    \n",
    "    tokens_length = [len(x) for x in tokens_input]\n",
    "    \n",
    "    maxTokenLength = max(tokens_length)\n",
    "    \n",
    "    \n",
    "    for x in tokens_input:\n",
    "        if(len(x) < maxTokenLength):\n",
    "            for y in range(maxTokenLength - len(x)):\n",
    "                x.append(\"\")\n",
    "    print(tokens_input)\n",
    "            \n",
    "    embeddings = elmo(inputs={\"tokens\": tokens_input,\"sequence_len\": tokens_length},\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    tokens_input = [list(filter(None,x)) for x in tokens_input if x]\n",
    "    for x in range(len(tokens_input)):\n",
    "        sent = tokens_input[x]\n",
    "        for i in range(len(sent)):\n",
    "            tokens.append(sess.run(embeddings[x][i]))\n",
    "            labels.append(sent[i])  \n",
    "\n",
    "    tsne_model = TSNE(perplexity=6, n_components=2, init='random', n_iter=500)\n",
    "    new_values = tsne_model.fit_transform(tokens,verbose=1)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(18, 12)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(splitLine,maxTokenLength)\n",
    "# tsne_plot(splitLine,maxTokenLength)\n",
    "# print(\"Plot created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Imported\n"
     ]
    }
   ],
   "source": [
    "print(\"Functions Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes the paragraph associated with a query\n",
    "# Returns the unique words without stopwords\n",
    "def formatQueryParagraph(queryText,stem):\n",
    "    queryParagraph = [x.strip() for x in queryText.split(\" \") if x not in stopWords]\n",
    "    if(stem):\n",
    "        return ' '.join(set(stemmer.stem(word) for word in queryParagraph))\n",
    "    return ' '.join(set(word for word in queryParagraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create map of word to top n simiar words.\n",
    "# This uses the embedding of each word to find the most similar words\n",
    "# Returns a string mapping the top n words related to each word in the query.\n",
    "# Removes any words that exist in the original query\n",
    "def independentN(queryWords,stem,n):\n",
    "    independentSimilar = \"\"\n",
    "    independentSimilarList = []\n",
    "    queryWords = queryWords.split(\" \")\n",
    "#     print(queryWords)\n",
    "    vocab = glove_model.wv.vocab\n",
    "#     print([word for word in queryWords])\n",
    "#     print([word in vocab for word in queryWords])\n",
    "    similarMap = [(word,glove_model.most_similar(positive=[word],topn=n)) for word in queryWords if word in vocab]\n",
    "#     print(similarMap)\n",
    "#     print(similarMap)\n",
    "    for key,value in similarMap:\n",
    "        if(key in vocab):\n",
    "            if(stem):\n",
    "                independentSimilar = key +':' + ' '.join(set(stemmer.stem(x[0]) for x in value if x[0] not in queryWords))\n",
    "            else:\n",
    "                independentSimilar = key +':' + ' '.join(set(x[0] for x in value if x[0] not in queryWords))\n",
    "            independentSimilarList.append(independentSimilar)\n",
    "        else:\n",
    "            continue\n",
    "    return independentSimilarList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testParagraphFile = \"../Galago/data/paragraphCorpus.txt\"\n",
    "# sdmQueryFile = \"../Galago/Queries/sdm/rih-query.json\"\n",
    "\n",
    "# QrelMap is a map of qrel ID to \n",
    "def loadData (qrelMap, qrelTestMap, queryText,splitLine):\n",
    "    qrelText = \"../Java_API/Car-Grpc/src/main/resources/data/qrelMap-train.txt\"\n",
    "    qrelTestText = \"../Java_API/Car-Grpc/src/main/resources/data/qrelMap-test.txt\"\n",
    "#     queryFile = \"../Java_API/Car-Grpc/src/main/resources/Queries/Glove/rih-0-combine-query.json\"\n",
    "    paragraphFile = \"paragraphCorpus.txt\"\n",
    "    \n",
    "    with open(paragraphFile,'r') as f:\n",
    "        for line in f:\n",
    "            splitLine.append(list(filter(None,' '.join(line.split(\"__PERIOD__\")).split(\" \"))))\n",
    "\n",
    "#     with open(queryFile,'r') as f:\n",
    "#         p = re.compile(\"\\((.*?) \\)\")\n",
    "        \n",
    "#         for line in f:\n",
    "#             queryText += ' '.join([x.strip() for x in p.findall(line)])\n",
    "\n",
    "    with open(qrelText,'r') as f:\n",
    "        for line in f:\n",
    "            test = line.split(\":\")\n",
    "            \n",
    "            key = formatQuery(test[1],False).strip()\n",
    "    \n",
    "            value = formatQueryParagraph(test[2],False).strip()\n",
    "            if(key not in qrelMap):\n",
    "                qrelMap[key] = [value]\n",
    "            else:\n",
    "                qrelMap[key].append(value)\n",
    "                \n",
    "    with open(qrelTestText,'r') as f:\n",
    "        for line in f:\n",
    "            test = line.split(\":\")\n",
    "            \n",
    "            key = formatQuery(test[1],False).strip()\n",
    "    \n",
    "            value = formatQueryParagraph(test[2],False).strip()\n",
    "            if(key not in qrelTestMap):\n",
    "                qrelTestMap[key] = [value]\n",
    "            else:\n",
    "                qrelTestMap[key].append(value)                \n",
    "\n",
    "    print(\"loading complete\")\n",
    "#     return queryText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes a query Id in the form Aftertaste/Distinguishing%20aftertaste%20and%20flavor\n",
    "# Returns aftertaste distinguishing aftertaste flavor\n",
    "# Removes slashes, %20, and lower cases, as well as removing stopwords.\n",
    "def formatQuery(queryId,stem):\n",
    "    queryIdWords = [x.lower() for x in queryId.replace(\"/\",\" \").replace(\"%20\",\" \").split(\" \") if x.lower() not in stopWords]\n",
    "    if(stem == True):\n",
    "        return ' '.join(set(stemmer.stem(word) for word in queryIdWords)).strip()\n",
    "    else:\n",
    "        return ' '.join(list(dict.fromkeys(word for word in queryIdWords))).strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
